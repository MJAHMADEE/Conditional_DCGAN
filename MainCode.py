# -*- coding: utf-8 -*-
"""MJAhmadi_HW6_Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-3mCJX3TZ9EA0hR22X_Hw7FiqHmhvU06

# 2.1.

## A)
"""

# Commented out IPython magic to ensure Python compatibility.
# Import necessary libraries
import numpy as np
import random
import os
import shutil
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.utils.data as data
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.autograd import Variable
from PIL import Image
import PIL.ImageOps
from matplotlib import pyplot as plt
from tqdm import tqdm
import time
# store starting time
begin = time.time()

# Install the medmnist package
!pip install medmnist

# Import the medmnist package and its sub-modules
import medmnist
from medmnist import INFO, Evaluator

# Set matplotlib to inline mode
# %matplotlib inline

# Set matplotlib backend to TkAgg
# matplotlib.use("TkAgg")

import medmnist
from torchvision import transforms
from torch.utils.data import DataLoader
import os

# Define the root directory for saving the data
root_dir = '/content/data/MedMNIST'  # Specify the desired root directory path

# Create the root directory if it does not exist
os.makedirs(root_dir, exist_ok=True)

dataset_name = "breastmnist"  # The name of the dataset
download = True  # Flag to download the dataset if not available locally
dataset_name = dataset_name.lower()  # Convert the dataset name to lowercase

NUM_EPOCHS = 15  # Number of epochs for training
BATCH_SIZE = 128  # Batch size for data loading
lr = 0.001  # Learning rate for the optimizer

info = INFO[dataset_name]  # Retrieve information about the dataset
task = info['task']  # The task associated with the dataset

DataClass = getattr(medmnist, info['python_class'])  # Get the data class for the dataset

# Data preprocessing transforms
data_transform = transforms.Compose([
    # transforms.Resize(224),
    # transforms.Lambda(lambda image: image.convert('RGB')),
    transforms.ToTensor(),  # Convert data to tensors
    transforms.Normalize(mean=[.5], std=[.5])  # Normalize the data
])

# Load the training and testing datasets
train_dataset = DataClass(split='train', transform=data_transform, download=download, root=root_dir)
test_dataset = DataClass(split='test', transform=data_transform, download=download, root=root_dir)
val_dataset = DataClass(split='val', transform=data_transform, download=download, root=root_dir)
pil_dataset = DataClass(split='train', download=download, root=root_dir)  # Load the PIL dataset for visualization (if needed)

# Create data loaders for training and testing datasets
train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = data.DataLoader(dataset=val_dataset, batch_size=2*BATCH_SIZE, shuffle=False)
test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)

# Get the labels from the train_dataset
labels = train_dataset.labels

# Find the unique classes in the dataset
unique_classes = np.unique(labels)

# Calculate the number of classes
num_classes = len(unique_classes)

# Print the number of classes
print("Number of classes in the dataset:", num_classes)

# Verify the number of classes by accessing the label information directly from the train_dataset
print("Label info of dataset:", train_dataset.info['label'])

# Print the complete information of the train_dataset
print("Info of dataset:", train_dataset.info)

train_dataset.info

# Calculate the number of channels in the image

# Access the first sample of the train_dataset and retrieve the image
image = train_dataset[0][0]

# Get the number of channels in the image
num_channels = image.shape[0]

# Print the number of channels
print("Number of channels of the image:", num_channels)

# Display an image from a specific class with class label written above the image
import matplotlib.pyplot as plt

# Get the index and class label of the image
index = 1
class_label = train_dataset[index][1][0]

# Reshape and visualize the image
image = train_dataset[index][0].reshape((28, 28))

# Create a figure and axes
fig, ax = plt.subplots()

# Display the image
ax.imshow(image, cmap='gray')

# Write the class label above the image
ax.set_title(f"Class: {class_label}", fontsize=12, pad=10)

# Remove the axis ticks
ax.set_xticks([])
ax.set_yticks([])

# Save the figure as a PDF file with index and class label in the filename
filename = f"image_{index}_class_{class_label}.pdf"
plt.savefig(filename, format='pdf')

# Show the plot
plt.show()

# Display an image from a specific class with class label written above the image
import matplotlib.pyplot as plt

# Get the index and class label of the image
index = 200
class_label = train_dataset[index][1][0]

# Reshape and visualize the image
image = train_dataset[index][0].reshape((28, 28))

# Create a figure and axes
fig, ax = plt.subplots()

# Display the image
ax.imshow(image, cmap='gray')

# Write the class label above the image
ax.set_title(f"Class: {class_label}", fontsize=12, pad=10)

# Remove the axis ticks
ax.set_xticks([])
ax.set_yticks([])

# Save the figure as a PDF file with index and class label in the filename
filename = f"image_{index}_class_{class_label}.pdf"
plt.savefig(filename, format='pdf')

# Show the plot
plt.show()

# Display images from different classes with class labels and image indices written above the images in a 5x3 grid

import matplotlib.pyplot as plt

# Set the number of rows and columns for the grid
num_rows = 5
num_cols = 5

# Create a figure and axes
fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 10))

# Iterate over the images and their class labels
for i in range(num_rows * num_cols):
    # Get the class label of the image
    class_label = train_dataset[i][1][0]

    # Reshape the image
    image = train_dataset[i][0].reshape((28, 28))

    # Determine the row and column index for the current subplot
    row = i // num_cols
    col = i % num_cols

    # Display the image in the corresponding subplot
    axes[row, col].imshow(image, cmap='gray')
    axes[row, col].set_title(f"Image: {i}\nClass: {class_label}", fontsize=10, pad=4)
    axes[row, col].axis('off')

# Adjust the spacing between subplots
fig.tight_layout()

# Save the figure as a PDF file
plt.savefig('images_with_class_labels.pdf', format='pdf')

# Show the plot
plt.show()

# Calculate and display the number of images in each class

# Get the labels from the train_dataset
labels = train_dataset.labels

# Calculate the total number of images
total_images = len(labels)

# Calculate the number of images labeled as '1'
class_1_images = np.sum(labels)

# Calculate the number of images labeled as '0'
class_0_images = total_images - class_1_images

# Display the number of images in each class
print("Number of images in class '0':", class_0_images)
print("Number of images in class '1':", class_1_images)

# Save the results as a PDF file
fig, ax = plt.subplots()
ax.bar(['Class 0', 'Class 1'], [class_0_images, class_1_images])
ax.set_ylabel('Number of Images')
ax.set_title('Number of Images in Each Class')

plt.savefig('class_distribution.pdf', format='pdf')

# Show the plot
plt.show()

print(train_dataset)
print("===================")
print(test_dataset)

# montage

train_dataset.montage(length=20)

"""## B)"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import torchvision.transforms as transform
from matplotlib import pyplot as plt
from tqdm import tqdm
from torchvision import transforms

# Define variable names and add comments

dataset_name = "breastmnist"  # The name of the dataset
download = True  # Flag to download the dataset if not available locally
dataset_name = dataset_name.lower()  # Convert the dataset name to lowercase

NUM_EPOCHS = 5  # Number of epochs for training
BATCH_SIZE = 128  # Batch size for data loading
lr = 0.0001  # Learning rate for the optimizer

info = INFO[dataset_name]  # Retrieve information about the dataset
task = info['task']  # The task associated with the dataset

DataClass = getattr(medmnist, info['python_class'])  # Get the data class for the dataset

# Data preprocessing transforms
data_transform = transforms.Compose([
    transforms.Resize(224),  # Resize the image to 224x224
    transforms.Grayscale(3),  # Convert the image to RGB format
    transforms.ToTensor(),  # Convert data to tensors
    transforms.Normalize(mean=[.5], std=[.5])  # Normalize the data
])

# Load the training and testing datasets
train_dataset = DataClass(split='train', transform=data_transform, download=download)
test_dataset = DataClass(split='test', transform=data_transform, download=download)
val_dataset = DataClass(split='val', transform=data_transform, download=download)
pil_dataset = DataClass(split='train', download=download)  # Load the PIL dataset for visualization (if needed)

# Create data loaders for training and testing datasets
train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = data.DataLoader(dataset=val_dataset, batch_size=78, shuffle=False)
test_loader = data.DataLoader(dataset=test_dataset, batch_size=156, shuffle=False)

# Import ResNet-50 model
import torchvision.models as models

# Load the pre-trained ResNet-50 model
model = models.resnet50(pretrained=True)

# Replace the last fully connected layer to match the number of output classes
num_classes = len(info['label'])
model.fc = nn.Linear(model.fc.in_features, num_classes)

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=lr)

# Training loop
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

train_losses = []
val_losses = []
train_accs = []
val_accs = []

for epoch in range(NUM_EPOCHS):
    train_loss = 0.0
    val_loss = 0.0
    train_total = 0
    train_correct = 0
    val_total = 0
    val_correct = 0

    # Training
    model.train()
    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - Training'):
        images = images.to(device)
        labels = labels.squeeze().to(device)  # Convert multi-target labels to single-valued labels

        optimizer.zero_grad()

        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item() * images.size(0)

        _, predicted = torch.max(outputs.data, 1)
        train_total += labels.size(0)
        train_correct += (predicted == labels).sum().item()

    # Validation
    model.eval()
    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - Validation'):
            images = images.to(device)
            labels = labels.squeeze().to(device)  # Convert multi-target labels to single-valued labels

            outputs = model(images)
            loss = criterion(outputs, labels)

            val_loss += loss.item() * images.size(0)

            _, predicted = torch.max(outputs.data, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    # Calculate metrics
    train_loss /= len(train_loader.dataset)
    val_loss /= len(val_loader.dataset)
    train_accuracy = train_correct / train_total
    val_accuracy = val_correct / val_total

    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accs.append(train_accuracy)
    val_accs.append(val_accuracy)

    print(f'Epoch {epoch+1}/{NUM_EPOCHS} - Training Loss: {train_loss:.4f} - Training Accuracy: {train_accuracy:.4f} - Validation Loss: {val_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}')

# Plot loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')
plt.savefig('loss_plot.pdf')

plt.figure(figsize=(10, 5))
plt.plot(train_accs, label='Training Accuracy')
plt.plot(val_accs, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')
plt.savefig('accuracy_plot.pdf')

# Classification report on the test split
model.eval()
test_total = 0
test_correct = 0
test_predictions = []
test_targets = []

with torch.no_grad():
    for images, labels in tqdm(test_loader, desc='Test'):
        images = images.to(device)
        labels = labels.squeeze().to(device)  # Convert multi-target labels to single-valued labels

        outputs = model(images)

        _, predicted = torch.max(outputs.data, 1)
        test_total += labels.size(0)
        test_correct += (predicted == labels).sum().item()

        test_predictions.extend(predicted.cpu().numpy())
        test_targets.extend(labels.cpu().numpy())

test_accuracy = test_correct / test_total
print(f'Test Accuracy: {test_accuracy:.4f}')

# Print classification report
from sklearn.metrics import classification_report
target_names = info['label']
classification_rep = classification_report(test_targets, test_predictions, target_names=target_names)
print(classification_rep)

# Plot confusion matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(test_targets, test_predictions)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=target_names, yticklabels=target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.savefig('confusion_matrix_plot.pdf')

"""# 2.2. cDCGAN(Conditional DCGAN)"""

# Commented out IPython magic to ensure Python compatibility.
# Import necessary libraries
import numpy as np
import random
import os
import shutil
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.utils.data as data
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.autograd import Variable
from PIL import Image
import PIL.ImageOps
from matplotlib import pyplot as plt
from tqdm import tqdm

# Install the medmnist package
!pip install medmnist

# Import the medmnist package and its sub-modules
import medmnist
from medmnist import INFO, Evaluator

# Set matplotlib to inline mode
# %matplotlib inline

"""## Dataset"""

BATCH_SIZE = 64

import medmnist
from torchvision import transforms
from torch.utils.data import DataLoader
import os

# Define the root directory for saving the data
root_dir = '/content/data/MedMNIST'  # Specify the desired root directory path

# Create the root directory if it does not exist
os.makedirs(root_dir, exist_ok=True)

dataset_name = "breastmnist"  # The name of the dataset
download = True  # Flag to download the dataset if not available locally
dataset_name = dataset_name.lower()  # Convert the dataset name to lowercase

info = INFO[dataset_name]  # Retrieve information about the dataset
task = info['task']  # The task associated with the dataset

DataClass = getattr(medmnist, info['python_class'])  # Get the data class for the dataset

class MedMNISTDataset(DataClass):
    def __getitem__(self, index):
        image, label = super().__getitem__(index)
        return image, label.item()

# Data preprocessing transforms
data_transform = transforms.Compose([
    # transforms.Resize(224),
    # transforms.Lambda(lambda image: image.convert('RGB')),
    transforms.ToTensor(),  # Convert data to tensors
    transforms.Normalize((0.5,), (0.5,))
])

# Load the training and testing datasets
train_dataset = MedMNISTDataset(split='train', transform=data_transform, download=download, root=root_dir)
test_dataset = MedMNISTDataset(split='test', transform=data_transform, download=download, root=root_dir)
val_dataset = MedMNISTDataset(split='val', transform=data_transform, download=download, root=root_dir)
pil_dataset = DataClass(split='train', download=download, root=root_dir)  # Load the PIL dataset for visualization (if needed)

# Create data loaders for training and testing datasets
train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)
test_dataloader = DataLoader(dataset=test_dataset, batch_size=156, shuffle=False)

import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Define the transformation
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Print a sample of data and label from train_dataset
print("Sample from train_dataset:")
data, label = train_dataset[0]
print("Data shape:", data.shape)
print("Label:", label)

# Create the train_dataloader
train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)

# Print a sample of data and label from train_dataloader
print("\nSample from train_dataloader:")
data_batch, label_batch = next(iter(train_dataloader))
print("Data batch shape:", data_batch.shape)
print("Label batch shape:", label_batch.shape)
print("Data batch[0] shape:", data_batch[0].shape)
print("Label batch[0]:", label_batch[0])

"""## Model"""

import torch
import torch.nn as nn

class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()

        # Defining the linear layer
        self.linear_layer = nn.Sequential(nn.Linear(102, 7*7*128), nn.LeakyReLU())

        # Defining the main sequential module
        self.main = nn.Sequential(
            # Upsampling layer 1
            nn.ConvTranspose2d(128, 20, kernel_size=5),  # Output size: 11x11
            nn.BatchNorm2d(20),
            nn.ReLU(True),

            # Upsampling layer 2
            nn.ConvTranspose2d(20, 20, kernel_size=4),  # Output size: 14x14
            nn.BatchNorm2d(20),
            nn.ReLU(True),

            # Upsampling layer 3
            nn.ConvTranspose2d(20, 20, kernel_size=4),  # Output size: 17x17
            nn.BatchNorm2d(20),
            nn.ReLU(True),

            # Upsampling layer 4
            nn.ConvTranspose2d(20, 20, kernel_size=4),  # Output size: 20x20
            nn.BatchNorm2d(20),
            nn.ReLU(True),

            # Upsampling layer 5
            nn.ConvTranspose2d(20, 20, kernel_size=4),  # Output size: 23x23
            nn.BatchNorm2d(20),
            nn.ReLU(True),

            # Upsampling layer 6
            nn.ConvTranspose2d(20, 20, kernel_size=3),  # Output size: 25x25
            nn.BatchNorm2d(20),
            nn.ReLU(True),

            # Final output layer
            nn.ConvTranspose2d(20, 1, kernel_size=4),  # Output size: 28x28
            nn.Tanh()
        )

    def forward(self, input, label):
        # Concatenating input and label along dimension 1
        concatenated_input = torch.cat([input, label], dim=1)
        # Input shape: 102

        # Applying linear layer
        linear_output = self.linear_layer(concatenated_input)  # Output shape: 6,272

        # Reshaping the linear output
        reshaped_output = linear_output.view(linear_output.size(0), 128, 7, 7)

        # Forward pass through the main sequential module
        output = self.main(reshaped_output)

        return output


# Creating random tensors for testing
random_input = torch.rand(size=(64, 100))
random_label = torch.rand(size=(64, 2))

# Creating an instance of the Generator class
generator = Generator()

# Forward pass through the generator
output = generator(random_input, random_label)

# Shape of the output
print(output.shape)

import torch
import torch.nn as nn

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()

        # Defining the linear layer
        self.linear_layer = nn.Sequential(nn.Linear(2, 7*7*16), nn.LeakyReLU())

        # Defining the main sequential module
        self.main = nn.Sequential(
            # Convolutional layer 1
            nn.Conv2d(2, 20, kernel_size=3),  # Input size: 26x26
            nn.LeakyReLU(0.2, inplace=True),

            # Convolutional layer 2
            nn.Conv2d(20, 30, kernel_size=3),  # Input size: 24x24
            nn.LeakyReLU(0.2, inplace=True),

            # Max pooling layer 1
            nn.MaxPool2d(2),  # Output size: 12x12

            # Convolutional layer 3
            nn.Conv2d(30, 30, kernel_size=3),  # Input size: 10x10
            nn.LeakyReLU(0.2, inplace=True),

            # Max pooling layer 2
            nn.MaxPool2d(2),  # Output size: 5x5

            # Convolutional layer 4
            nn.Conv2d(30, 20, kernel_size=3),  # Input size: 3x3
            nn.LeakyReLU(0.2, inplace=True),

            # Convolutional layer 5
            nn.Conv2d(20, 1, kernel_size=3),  # Input size: 1x1
            nn.Sigmoid()
        )

        self.flatten = nn.Flatten()

    def forward(self, images, label):
        # Applying linear layer and reshaping the output
        reshaped_label = self.linear_layer(label).view(label.size(0), 1, 28, 28)

        # Concatenating images and label along dimension 1
        concatenated_input = torch.cat([images, reshaped_label], dim=1)

        # Forward pass through the main sequential module
        output = self.main(concatenated_input)

        # Flattening the output tensor
        flattened_output = self.flatten(output)

        return flattened_output


# Creating random tensors for testing
label = torch.rand(size=(64, 2))
images = torch.rand(size=(64, 1, 28, 28))

# Creating an instance of the Discriminator class
discriminator = Discriminator()

# Forward pass through the discriminator
output = discriminator(images, label)

# Shape of the output
print(output.shape)

"""
## Train"""

# Some Configurations
# Setting the number of epochs for training
EPOCHS = 700

# Checking if CUDA is available and setting the device accordingly
device = 'cuda:0' if torch.cuda.is_available() else 'cpu'

# Setting the verbosity level for printing progress during training
# 0: Silent, 1: Minimal, 2: Moderate, 3: Verbose
VERBOSE = 3

# Setting a flag to save the generated plots
SAVE_PLOTS = True

# Setting a flag to visualize the plots during training
VISUALIZE_PLOTS = True

# Setting the directory path for saving the plots
SAVE_DIR = "./runs"

# Setting the model name
MODEL_NAME = "BreastMNIST_cDCGAN_Implementation"

# Choosing the optimizer for training
# Options: "Adam", "SGD"
OPTIMIZER = "Adam"

import os
import time
import math
from copy import deepcopy
import os.path as osp
import shutil
from prettytable import PrettyTable
import json

from tqdm import tqdm

import numpy as np
import torch
from torch.cuda import amp

# Import tensorboard
# from torch.utils.tensorboard import SummaryWriter

class Trainer:
    """
    Class for training a model.
    """

    def __init__(self, device=device, epochs=EPOCHS, batch_size=BATCH_SIZE, save_dir=SAVE_DIR, train_loader=train_dataloader, valid_loader=test_dataloader, weights=None, verbose=VERBOSE, visualize_plots=VISUALIZE_PLOTS, save_plots=SAVE_PLOTS, model_name=MODEL_NAME, optimizer=OPTIMIZER):
        """
        Initialize the Trainer object.

        Args:
            device (str): Device to use for training.
            epochs (int): Number of training epochs.
            batch_size (int): Batch size for training.
            save_dir (str): Directory to save the trained model.
            train_loader (DataLoader): DataLoader for training data.
            valid_loader (DataLoader): DataLoader for validation data.
            weights (str): Path to pretrained model weights.
            verbose (int): Level of verbosity for printing information during training.
            visualize_plots (bool): Whether to visualize training plots.
            save_plots (bool): Whether to save training plots.
            model_name (str): Name of the model.
            optimizer (str): Name of the optimizer to use.
        """
        self.device = device
        self.save_dir = save_dir
        self.batch_size = batch_size
        self.epochs = epochs
        self.use_ema = False
        self.model_name = model_name
        self.weights = weights
        self.visualize_plots = visualize_plots
        self.save_plots = save_plots
        # Verbosity levels: 0 = none, 1 = model architecture, 2 = optimizer information, 3 = model parameters
        self.verbose = verbose
        self.d_losses = []
        self.g_losses = []
        self.conf = {'Name': self.model_name, 'Batch_size': self.batch_size, 'Max_iter_num': '', 'Epochs': self.epochs, 'Trained_epoch': 0, 'Optimizer': '', "Model": '', 'Parameter_size': ''}
        self.optimizer_name = optimizer

        # Create a unique save directory
        temm = 0
        tmp_save_dir = self.save_dir
        while osp.exists(tmp_save_dir):
            tmp_save_dir = self.save_dir
            temm += 1
            tmp_save_dir += str(temm)
        self.save_dir = tmp_save_dir
        del temm

        # Get data loaders
        self.train_loader = train_loader
        self.valid_loader = valid_loader
        self.max_stepnum = len(self.train_loader)
        self.conf["Max_iter_num"] = self.max_stepnum

        # Get the model
        self.d_model, self.g_model = self.get_model()
        if self.verbose > 2:
            self.count_parameters(self.d_model)
            self.count_parameters(self.g_model)

        # Get the optimizer
        self.d_optimizer, self.g_optimizer = self.get_optimizer(optimizer=self.optimizer_name)

        # Initialize tensorboard
        # self.tblogger = SummaryWriter(self.save_dir)

    ## INITIALIZERS
    def get_model(self):
        """
        Get the Discriminator and Generator models.

        Returns:
            tuple: Tuple containing the Discriminator and Generator models.
        """
        # Get the Discriminator and Generator models from their respective classes.
        d_model = Discriminator().to(self.device)
        g_model = Generator().to(self.device)

        # Load pretrained weights if provided
        if self.weights:
            print(f'Loading state_dict from {self.weights} for fine-tuning...')
            g_model.load_state_dict(torch.load(self.weights))

        # Log model information
        if self.verbose > 0:
            print('Generator Model:\n', g_model)
            print('Discriminator Model:\n', d_model)
        self.conf["Generator Model"] = str(g_model)
        self.conf["Discriminator Model"] = str(d_model)

        return d_model, g_model

    def get_optimizer(self, optimizer="Adam", lr0=0.0001, beta1=0.5):
        """
        Get the Discriminator and Generator optimizers.

        Args:
            optimizer (str): Name of the optimizer to use. Options: "SGD" or "Adam" (default: "Adam").
            lr0 (float): Learning rate (default: 0.0002).
            beta1 (float): Beta1 parameter for Adam optimizer (default: 0.5).

        Returns:
            tuple: Tuple containing the Discriminator and Generator optimizers.
        """
        assert optimizer in ['SGD', 'Adam'], 'ERROR: Unknown optimizer, defaulting to SGD.'

        if optimizer == 'SGD':
            d_optim = torch.optim.SGD(self.d_model.parameters(), lr=lr0, momentum=0.5)
            g_optim = torch.optim.SGD(self.g_model.parameters(), lr=lr0, momentum=0.5)
        elif optimizer == 'Adam':
            d_optim = torch.optim.Adam(self.d_model.parameters(), lr=lr0, betas=(beta1, 0.999))
            g_optim = torch.optim.Adam(self.g_model.parameters(), lr=lr0, betas=(beta1, 0.999))

        if self.verbose > 1:
            print(f"Discriminator optimizer: {type(d_optim).__name__}")
            print(f"Generator optimizer: {type(g_optim).__name__}")

        self.conf['Generator Optimizer'] = f"Generator optimizer: {type(g_optim).__name__}"
        self.conf['Discriminator Optimizer'] = f"Discriminator optimizer: {type(d_optim).__name__}"

        return d_optim, g_optim

    def count_parameters(self, model):
        """
        Count the number of trainable parameters in a model.

        Args:
            model (nn.Module): The model to count parameters for.
        """
        table = PrettyTable(["Modules", "Parameters"])
        total_params = 0
        for name, parameter in model.named_parameters():
            if not parameter.requires_grad:
                continue
            params = parameter.numel()
            table.add_row([name, params])
            total_params += params
        print(table)
        print(f"Total Trainable Params: {total_params}")
        self.conf["Parameter_size"] = total_params

    def d_loss_function(self, inputs, targets):
        """
        Compute the loss for the Discriminator.

        Args:
            inputs (torch.Tensor): Discriminator inputs.
            targets (torch.Tensor): Discriminator targets.

        Returns:
            torch.Tensor: The loss value.
        """
        return nn.BCELoss()(inputs, targets)

    def g_loss_function(self, inputs):
        """
        Compute the loss for the Generator.

        Args:
            inputs (torch.Tensor): Generator inputs.

        Returns:
            torch.Tensor: The loss value.
        """
        targets = torch.ones([inputs.shape[0], 1]).to(device)
        return nn.BCELoss()(inputs, targets)

    ## TRAINING PROCESS
    def train_discriminator(self, batch_data):
        """
        Train the Discriminator model on a batch of data.

        Args:
            batch_data (tuple): Tuple containing the input data and labels.

        Returns:
            float: The loss value.
        """
        real_inputs = batch_data[0].to(device)
        real_labels = batch_data[1].to(device)

        real_onehot_label = F.one_hot(torch.arange(2), 2).to(self.device)[real_labels].float()

        real_outputs = self.d_model(real_inputs, real_onehot_label)
        real_label = torch.ones(real_inputs.shape[0], 1).to(device)

        noise = (torch.rand(real_inputs.shape[0], 100) - 0.5) / 0.5
        noise = noise.to(device)
        fake_inputs = self.g_model(noise, real_onehot_label)
        fake_outputs = self.d_model(fake_inputs, real_onehot_label)
        fake_label = torch.zeros(fake_inputs.shape[0], 1).to(device)

        outputs = torch.cat((real_outputs, fake_outputs), 0)
        targets = torch.cat((real_label, fake_label), 0)

        # Zero the parameter gradients
        self.d_optimizer.zero_grad()

        # Backward propagation
        d_loss = self.d_loss_function(outputs, targets)
        d_loss.backward()
        self.d_optimizer.step()
        return d_loss.item()

    def train_generator(self, batch_data):
        """
        Train the Generator model on a batch of data.

        Args:
            batch_data (tuple): Tuple containing the input data and labels.

        Returns:
            tuple: Tuple containing the loss value, generated inputs, and real labels.
        """
        real_inputs = batch_data[0].to(self.device)
        real_labels = batch_data[1].to(device)

        real_onehot_label = F.one_hot(torch.arange(2), 2).to(self.device)[real_labels].float()

        noise = (torch.rand(real_inputs.shape[0], 100) - 0.5) / 0.5
        noise = noise.to(device)

        fake_inputs = self.g_model(noise, real_onehot_label)
        fake_outputs = self.d_model(fake_inputs, real_onehot_label)

        g_loss = self.g_loss_function(fake_outputs)
        self.g_optimizer.zero_grad()
        g_loss.backward()
        self.g_optimizer.step()
        return g_loss.item(), fake_inputs, real_labels

    def train(self):
        """
        Train the models.

        This method performs the training process, including training the Discriminator and Generator models
        for the specified number of epochs.
        """
        try:
            # Training process prerequisite
            self.start_time = time.time()
            print('Start Training Process\nTime: {}'.format(time.ctime(self.start_time)))

            # Epoch Loop
            for self.epoch in range(0, self.epochs):
                try:
                    self.conf["Trained_epoch"] = self.epoch

                    # Training loop
                    self.g_model.train(True)
                    self.d_model.train(True)

                    pbar = enumerate(self.train_loader)
                    pbar = tqdm(pbar, total=self.max_stepnum)
                    for step, batch_data in pbar:
                        d_loss = self.train_discriminator(batch_data)
                        g_loss, fake_inputs, real_labels = self.train_generator(batch_data)

                        self.d_losses.append(d_loss)
                        self.g_losses.append(g_loss)
                        pbar.set_description(f"Epoch: {self.epoch}/{self.epochs}\tDiscriminator Loss: {d_loss}\tGenerator Loss: {g_loss}")
                    del pbar

                except Exception as _:
                    print('ERROR in training steps.')
                    raise

                if self.epoch % 10 == 0:
                    # Plot Losses
                    self.plot_loss()
                    imgs_numpy = (fake_inputs.data.cpu().numpy() + 1.0) / 2.0
                    sqrtn = int(np.ceil(np.sqrt(imgs_numpy[:64].shape[0])))
                    for index, image in enumerate(imgs_numpy[:64]):
                        plt.subplot(sqrtn, sqrtn, index + 1)
                        plt.imshow(image.reshape(28, 28), cmap='gray')

                    if self.save_plots:
                        save_img_dir = osp.join(self.save_dir, 'images')
                        if not osp.exists(save_img_dir):
                            os.makedirs(save_img_dir)
                        plt.savefig("{}/epoch-{}-img.pdf".format(save_img_dir, self.epoch))

                    if self.visualize_plots:
                        plt.show()
                    print(real_labels[:64])

                # Save Model and Configurations
                self.save()

        except Exception as _:
            print('ERROR in training loop or eval/save model.')
            raise
        finally:
            finish_time = time.time()
            # print(f'\nTraining completed in {time.ctime(finish_time)} \nIts Done in: {(time.time() - self.start_time) / 3600:.3f} hours.')


    ## Training Callback after each epoch
    def plot_loss(self, train_mean_size=1, val_mean_size=1):
        """
        Plot the training and validation losses.

        Args:
            train_mean_size (int): Size of the training mean.
            val_mean_size (int): Size of the validation mean.
        """
        COLS = 3
        ROWS = 1
        LINE_WIDTH = 2
        fig, ax = plt.subplots(ROWS, COLS, figsize=(COLS * 10, ROWS * 10))

        ax[0].plot(np.arange(len(self.d_losses) / train_mean_size),
                   np.mean(np.array(self.d_losses).reshape(-1, train_mean_size), axis=1), 'r',
                   label="training loss", linewidth=LINE_WIDTH)
        ax[0].set_title("Discriminator Loss")
        ax[1].plot(np.arange(len(self.g_losses) / val_mean_size),
                   np.mean(np.array(self.g_losses).reshape(-1, val_mean_size), axis=1), 'g',
                   label="validation loss", linewidth=LINE_WIDTH)
        ax[1].set_title("Generator Loss")
        ax[2].plot(np.arange(len(self.d_losses) / train_mean_size),
                   np.mean(np.array(self.d_losses).reshape(-1, train_mean_size), axis=1), 'r',
                   label="training loss", linewidth=LINE_WIDTH)
        ax[2].plot(np.arange(len(self.g_losses) / val_mean_size),
                   np.mean(np.array(self.g_losses).reshape(-1, val_mean_size), axis=1), 'g',
                   label="validation loss", linewidth=LINE_WIDTH)
        ax[2].set_title("Dis/Gen Loss")

        if self.save_plots:
            save_plot_dir = osp.join(self.save_dir, 'plots')
            if not osp.exists(save_plot_dir):
                os.makedirs(save_plot_dir)
            plt.savefig("{}/epoch-{}-loss-plot.pdf".format(save_plot_dir, self.epoch))
        if self.visualize_plots:
            plt.show()

    ## Save Model
    def save(self):
        """
        Save the trained model and configurations.
        """
        # Create config object
        conf = json.dumps(self.conf)
        f = open(self.save_dir + "/config.json", "w")
        f.write(conf)
        f.close()

        # Save model
        save_ckpt_dir = osp.join(self.save_dir, 'weights')
        if not osp.exists(save_ckpt_dir):
            os.makedirs(save_ckpt_dir)
        filename = osp.join(save_ckpt_dir, self.model_name + "-" + str(self.epoch) + '.pt')
        torch.save(self.g_model.state_dict(), filename)

## Train the models
Trainer().train()

cp -r /content/runs /content/drive/MyDrive/HW6/Q2

"""# 2.3."""

import torch
from torchvision.utils import save_image

# Function to generate samples for a given class
def generate_samples(generator, class_label, num_samples):
    noise = torch.randn(num_samples, 100).to(device)
    label = torch.ones(num_samples, 2).to(device)
    label[:, class_label] = 1.0
    generator = generator.to(device)  # Move generator to the same device as noise and label
    generated_images = generator(noise, label)
    return generated_images

# Generate samples for class 0
class_0_samples = generate_samples(generator, 0, 2000)

# Generate samples for class 1
class_1_samples = generate_samples(generator, 1, 2000)

# Calculate the minimum number of samples per class
min_samples_per_class = min(len(class_0_samples), len(class_1_samples))

# Trim the generated samples to have the same number of samples per class
class_0_samples = class_0_samples[:min_samples_per_class]
class_1_samples = class_1_samples[:min_samples_per_class]

# Save the generated samples with suitable format and label in a dataloader
class_0_dataset = torch.utils.data.TensorDataset(class_0_samples, torch.zeros(min_samples_per_class))
class_1_dataset = torch.utils.data.TensorDataset(class_1_samples, torch.ones(min_samples_per_class))

generated_dataloader = torch.utils.data.DataLoader(
    torch.utils.data.ConcatDataset([class_0_dataset, class_1_dataset]),
    batch_size=BATCH_SIZE,
    shuffle=True
)

# Add the generated data to the train_dataloader
new_train_dataloader = torch.utils.data.DataLoader(
    torch.utils.data.ConcatDataset([train_dataset, generated_dataloader.dataset]),
    batch_size=BATCH_SIZE,
    shuffle=True
)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Function to generate samples for a given class
def generate_samples(generator, class_label, num_samples):
    noise = torch.randn(num_samples, 100).to(device)
    label = torch.ones(num_samples, 2).to(device)
    label[:, class_label] = 1.0
    generator = generator.to(device)  # Move generator to the same device as noise and label
    generated_images = generator(noise, label)
    return generated_images

# Generate samples for class 0
class_0_samples = generate_samples(generator, 0, 2000)

# Generate samples for class 1
class_1_samples = generate_samples(generator, 1, 2000)

# Save the generated samples with suitable format and label in a dataloader
class_0_dataset = torch.utils.data.TensorDataset(class_0_samples, torch.zeros(2000))
class_1_dataset = torch.utils.data.TensorDataset(class_1_samples, torch.ones(2000))

generated_dataloader = torch.utils.data.DataLoader(
    torch.utils.data.ConcatDataset([class_0_dataset, class_1_dataset]),
    batch_size=BATCH_SIZE,
    shuffle=True
)

# Add the generated data to the train_dataloader
new_train_dataloader = torch.utils.data.DataLoader(
    torch.utils.data.ConcatDataset([train_dataset, generated_dataloader.dataset]),
    batch_size=BATCH_SIZE,
    shuffle=True
)

class_0_samples = len(class_0_dataset)
class_1_samples = len(class_1_dataset)

print("Number of samples in class 0 dataset:", class_0_samples)
print("Number of samples in class 1 dataset:", class_1_samples)

import torchvision.transforms as transforms

data_transform = transforms.Compose([
    transforms.Resize(224),  # Resize the image to 224x224
    transforms.Grayscale(3),  # Convert the image to RGB format
    transforms.ToTensor(),  # Convert data to tensors
    transforms.Normalize(mean=[.5], std=[.5])  # Normalize the data
])

# Apply transformations to train_dataset
train_dataset.transform = data_transform

# Apply transformations to val_dataset
val_dataset.transform = data_transform

# Apply transformations to test_dataset
test_dataset.transform = data_transform

# Update train_loader
train_loader = data.DataLoader(
    torch.utils.data.ConcatDataset([train_dataset, generated_dataloader.dataset]), batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True
)

# Update val_loader
val_loader = data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True
)

# Update test_loader
test_loader = data.DataLoader(
    test_dataset, batch_size=156, shuffle=False, num_workers=4, pin_memory=True
)

test_loader = test_dataloader
val_loader = val_dataloader
train_loader = new_train_dataloader

# Create data loaders
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)

def collate_tensor_fn(batch, collate_fn_map):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    if device.type == 'cuda':
        return torch.stack(batch, 0)
    else:
        return torch.stack(batch, 0, out=torch.tensor([], dtype=torch.float32))

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import torchvision.transforms as transform
from matplotlib import pyplot as plt
from tqdm import tqdm
from torchvision import transforms

# Define variable names and add comments

dataset_name = "breastmnist"  # The name of the dataset
download = True  # Flag to download the dataset if not available locally
dataset_name = dataset_name.lower()  # Convert the dataset name to lowercase

NUM_EPOCHS = 5  # Number of epochs for training
BATCH_SIZE = 64  # Batch size for data loading
lr = 0.0001  # Learning rate for the optimizer


# Import ResNet-50 model
import torchvision.models as models

# Load the pre-trained ResNet-50 model
model = models.resnet50(pretrained=True)

# Replace the last fully connected layer to match the number of output classes
num_classes = 10
model.fc = nn.Linear(model.fc.in_features, num_classes)

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=lr)

# Training loop
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

train_losses = []
val_losses = []
train_accs = []
val_accs = []

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

for epoch in range(NUM_EPOCHS):
    train_loss = 0.0
    val_loss = 0.0
    train_total = 0
    train_correct = 0
    val_total = 0
    val_correct = 0

    # Training
    model.train()
    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - Training'):
        images = images.to(device)
        labels = labels.squeeze().to(device)  # Convert multi-target labels to single-valued labels

        optimizer.zero_grad()

        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item() * images.size(0)

        _, predicted = torch.max(outputs.data, 1)
        train_total += labels.size(0)
        train_correct += (predicted == labels).sum().item()

    # Validation
    model.eval()
    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - Validation'):
            images = images.to(device)
            labels = labels.squeeze().to(device)  # Convert multi-target labels to single-valued labels

            outputs = model(images)
            loss = criterion(outputs, labels)

            val_loss += loss.item() * images.size(0)

            _, predicted = torch.max(outputs.data, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    # Calculate metrics
    train_loss /= len(train_loader.dataset)
    val_loss /= len(val_loader.dataset)
    train_accuracy = train_correct / train_total
    val_accuracy = val_correct / val_total

    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accs.append(train_accuracy)
    val_accs.append(val_accuracy)

    print(f'Epoch {epoch+1}/{NUM_EPOCHS} - Training Loss: {train_loss:.4f} - Training Accuracy: {train_accuracy:.4f} - Validation Loss: {val_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}')

# Plot loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')
plt.savefig('loss_plot.pdf')

plt.figure(figsize=(10, 5))
plt.plot(train_accs, label='Training Accuracy')
plt.plot(val_accs, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')
plt.savefig('accuracy_plot.pdf')

# Classification report on the test split
model.eval()
test_total = 0
test_correct = 0
test_predictions = []
test_targets = []

with torch.no_grad():
    for images, labels in tqdm(test_loader, desc='Test'):
        images = images.to(device)
        labels = labels.squeeze().to(device)  # Convert multi-target labels to single-valued labels

        outputs = model(images)

        _, predicted = torch.max(outputs.data, 1)
        test_total += labels.size(0)
        test_correct += (predicted == labels).sum().item()

        test_predictions.extend(predicted.cpu().numpy())
        test_targets.extend(labels.cpu().numpy())

test_accuracy = test_correct / test_total
print(f'Test Accuracy: {test_accuracy:.4f}')

# Print classification report
from sklearn.metrics import classification_report
target_names = info['label']
classification_rep = classification_report(test_targets, test_predictions, target_names=target_names)
print(classification_rep)

# Plot confusion matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(test_targets, test_predictions)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=target_names, yticklabels=target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.savefig('confusion_matrix_plot.pdf')

"""# Other Implementations"""

import os
import time
import math
from copy import deepcopy
import os.path as osp
import shutil
from prettytable import PrettyTable
import json

from tqdm import tqdm

import numpy as np
import torch
from torch.cuda import amp
# from torch.utils.tensorboard import SummaryWriter

class Trainer:
    # -----------------------------------------------INITIALIZE TRAINING-------------------------------------------------------------
    def __init__(self, device=device, epochs=EPOCHS, batch_size=BATCH_SIZE, save_dir=SAVE_DIR, train_loader=train_dataloader, valid_loader=test_dataloader, weights=None, verbose=VERBOSE, visualize_plots=VISUALIZE_PLOTS, save_plots=SAVE_PLOTS, model_name=MODEL_NAME, optimizer=OPTIMIZER):
        self.device = device
        self.save_dir = save_dir
        self.batch_size = batch_size
        self.epochs = epochs
        self.use_ema = False
        self.model_name = model_name
        self.weights = weights
        self.visualize_plots = visualize_plots
        self.save_plots = save_plots
        # 0 == nothing || 1 == model architecture || 2 == print optimizer || 3 == model parameters
        self.verbose = verbose
        self.d_losses=[]
        self.g_losses=[]
        self.conf = {'Name' : self.model_name, 'Bacth_size' : self.batch_size, 'Max_iter_num' : '', 'Epochs' : self.epochs, 'Trained_epoch' : 0, 'Optimizer' : '', "Model" : '', 'Parameter_size' : ''}
        self.optimizer_name = optimizer

        temm=0
        tmp_save_dir = self.save_dir
        while osp.exists(tmp_save_dir):
            tmp_save_dir = self.save_dir
            temm+=1
            tmp_save_dir += (str(temm))
        self.save_dir = tmp_save_dir
        del temm


        # get data loader
        self.train_loader, self.valid_loader = train_loader, valid_loader
        self.max_stepnum = len(self.train_loader)
        self.conf["Max_iter_num"] = self.max_stepnum

        # get model
        self.d_model, self.g_model = self.get_model()
        if self.verbose > 2:
            self.count_parameters(self.d_model)
            self.count_parameters(self.g_model)

        # Get optimizer
        self.d_optimizer, self.g_optimizer = self.get_optimizer(optimizer=self.optimizer_name)

        # tensorboard
        # self.tblogger = SummaryWriter(self.save_dir)

# ----------------------------------------------------INITIALIZERS-------------------------------------------------------------------------
    # Get Model
    def get_model(self):
        # Get Model Archutecture From Model Class.
        d_model = Discriminator().to(self.device)
        g_model = Generator().to(self.device)

        # finetune if pretrained model is set
        if self.weights:
            print(f'Loading state_dict from {self.weights} for fine-tuning...')
            g_model.load_state_dict(torch.load(self.weights))
        # Log Model
        if self.verbose > 0:
            print('Generator Model: {}\nDescriminator Model: {}'.format(g_model, d_model))
        self.conf["Generator Model"] = str(g_model)
        self.conf["Descriminator Model"] = str(d_model)
        return d_model, g_model

    def get_optimizer(self, optimizer="Adam", lr0=0.0002, beta1 = 0.5):
        assert optimizer == 'SGD' or 'Adam', 'ERROR: unknown optimizer, use SGD defaulted'
        if optimizer == 'SGD':
            d_optim = torch.optim.SGD(self.d_model.parameters(), lr=lr0, momentum=0.5)
            g_optim = torch.optim.SGD(self.g_model.parameters(), lr=lr0, momentum=0.5)
        elif optimizer == 'Adam':
            d_optim = torch.optim.Adam(self.d_model.parameters(), lr=lr0, betas=(beta1, 0.999))
            g_optim = torch.optim.Adam(self.g_model.parameters(), lr=lr0, betas=(beta1, 0.999))

        if self.verbose > 1:
            print(f"{'Descriminator optimizer:'} {type(d_optim).__name__}")
            print(f"{'Generator optimizer:'} {type(g_optim).__name__}")

        self.conf['Generator Optimizer'] = f"{'Generator optimizer:'} {type(g_optim).__name__}"
        self.conf['Descriminator Optimizer'] = f"{'Descriminator optimizer:'} {type(d_optim).__name__}"

        return d_optim, g_optim

    def count_parameters(self, model):
        table = PrettyTable(["Modules", "Parameters"])
        total_params = 0
        for name, parameter in model.named_parameters():
            if not parameter.requires_grad: continue
            params = parameter.numel()
            table.add_row([name, params])
            total_params+=params
        print(table)
        print(f"Total Trainable Params: {total_params}")
        self.conf["Parameter_size"] = total_params

    def d_loss_function(self, inputs, targets):
        return nn.BCELoss()(inputs, targets)


    def g_loss_function(self, inputs):
        targets = torch.ones([inputs.shape[0], 1])
        targets = targets.to(device)
        return nn.BCELoss()(inputs, targets)
# -------------------------------------------------------------------------------TRAINING PROCESS-----------------------------------------------
    def train_discriminator(self, batch_data):
        real_inputs = batch_data[0].to(device)
        real_labels = batch_data[1].to(device)
        # print(real_inputs.shape)
        # print(real_labels)

        real_onehot_label = F.one_hot(torch.arange(2), 2).to(self.device)[real_labels].float()
        # print(real_onehot_label)
        real_outputs = self.d_model(real_inputs, real_onehot_label)

        real_label = torch.ones(real_inputs.shape[0], 1).to(device)

        noise = (torch.rand(real_inputs.shape[0], 100) - 0.5) / 0.5
        noise = noise.to(device)
        fake_inputs = self.g_model(noise, real_onehot_label)
        # print(fake_inputs.shape)
        fake_outputs = self.d_model(fake_inputs, real_onehot_label)
        fake_label = torch.zeros(fake_inputs.shape[0], 1).to(device)

        outputs = torch.cat((real_outputs, fake_outputs), 0)
        targets = torch.cat((real_label, fake_label), 0)

        # Zero the parameter gradients
        self.d_optimizer.zero_grad()

        # Backward propagation
        d_loss = self.d_loss_function(outputs, targets)
        d_loss.backward()
        self.d_optimizer.step()
        return d_loss.item()

    def train_generator(self, batch_data):
        real_inputs = batch_data[0].to(self.device)
        real_labels = batch_data[1].to(device)

        real_onehot_label = F.one_hot(torch.arange(2), 2).to(self.device)[real_labels].float()

        noise = (torch.rand(real_inputs.shape[0], 100)-0.5)/0.5
        noise = noise.to(device)

        fake_inputs = self.g_model(noise, real_onehot_label)
        fake_outputs = self.d_model(fake_inputs, real_onehot_label)

        g_loss = self.g_loss_function(fake_outputs)
        self.g_optimizer.zero_grad()
        g_loss.backward()
        self.g_optimizer.step()
        return g_loss.item(), fake_inputs, real_labels

    # Training Process
    def train(self):
        try:
            # training process prerequisite
            self.start_time = time.time()
            print('Start Training Process \nTime: {}'.format(time.ctime(self.start_time)))

            # Epoch Loop
            for self.epoch in range(0, self.epochs):
                try:
                    self.conf["Trained_epoch"] = self.epoch
                    # Training loop
                    self.g_model.train(True)
                    self.d_model.train(True)

                    pbar = enumerate(self.train_loader)
                    pbar = tqdm(pbar, total=self.max_stepnum)
                    for step, batch_data in pbar:
                        d_loss = self.train_discriminator(batch_data)
                        g_loss, fake_inputs, real_labels = self.train_generator(batch_data)

                        self.d_losses.append(d_loss)
                        self.g_losses.append(g_loss)
                        pbar.set_description(f"Epoch: {self.epoch}/{self.epochs}\tDescriminator Loss: {d_loss}\Generator Loss: {g_loss}")
                    del pbar

                except Exception as _:
                    print('ERROR in training steps.')
                    raise
                if self.epoch % 10 == 0:
                    # PLot Losses
                    self.plot_loss()
                    imgs_numpy = (fake_inputs.data.cpu().numpy()+1.0)/2.0
                    sqrtn = int(np.ceil(np.sqrt(imgs_numpy[:64].shape[0])))
                    for index, image in enumerate(imgs_numpy[:64]):
                        plt.subplot(sqrtn, sqrtn, index+1)
                        plt.imshow(image.reshape(28, 28), cmap='gray')

                    if self.save_plots:
                        save_img_dir = osp.join(self.save_dir, 'images')
                        if not osp.exists(save_img_dir):
                            os.makedirs(save_img_dir)
                        plt.savefig("{}/epoch-{}-img.pdf".format(save_img_dir, self.epoch))

                    if self.visualize_plots:
                        plt.show()
                    print(real_labels[:64])

                # Save Model and Configurations
                self.save()

        except Exception as _:
            print('ERROR in training loop or eval/save model.')
            raise
        finally:
            finish_time = time.time()
            # print(f'\nTraining completed in {time.ctime(finish_time)} \nIts Done in: {(time.time() - self.start_time) / 3600:.3f} hours.')


    # -------------------------------------------------------Training Callback after each epoch--------------------------
    def plot_loss(self, train_mean_size=1, val_mean_size=1):
        COLS=3
        ROWS=1
        LINE_WIDTH = 2
        fig, ax = plt.subplots(ROWS, COLS, figsize=(COLS*10, ROWS*10))

        # train_mean_size = self.max_stepnum/self.batch_size

        ax[0].plot(np.arange(len(self.d_losses) / train_mean_size), np.mean(np.array(self.d_losses).reshape(-1, train_mean_size), axis=1), 'r',  label="training loss", linewidth=LINE_WIDTH)
        ax[0].set_title("Discriminator Loss")
        ax[1].plot(np.arange(len(self.g_losses) / val_mean_size), np.mean(np.array(self.g_losses).reshape(-1, val_mean_size), axis=1), 'g',  label="validation loss", linewidth=LINE_WIDTH)
        ax[1].set_title("Generator Loss")
        ax[2].plot(np.arange(len(self.d_losses) / train_mean_size), np.mean(np.array(self.d_losses).reshape(-1, train_mean_size), axis=1), 'r',  label="training loss", linewidth=LINE_WIDTH)
        ax[2].plot(np.arange(len(self.g_losses) / val_mean_size), np.mean(np.array(self.g_losses).reshape(-1, val_mean_size), axis=1), 'g',  label="validation loss", linewidth=LINE_WIDTH)
        ax[2].set_title("Dis/Gen Loss")
        if self.save_plots:
            save_plot_dir = osp.join(self.save_dir, 'plots')
            if not osp.exists(save_plot_dir):
                os.makedirs(save_plot_dir)
            plt.savefig("{}/epoch-{}-loss-plot.pdf".format(save_plot_dir, self.epoch))
        if self.visualize_plots:
            plt.show()

    # -------------------------------------------------------save Model-------------------------------------------
    def save(self):
        # create config object
        conf = json.dumps(self.conf)
        f = open(self.save_dir + "/config.json","w")
        f.write(conf)
        f.close()
        # save model
        save_ckpt_dir = osp.join(self.save_dir, 'weights')
        if not osp.exists(save_ckpt_dir):
            os.makedirs(save_ckpt_dir)
        filename = osp.join(save_ckpt_dir, self.model_name + "-" + str(self.epoch) + '.pt')
        torch.save(self.g_model.state_dict(), filename)

Trainer().train()

import torch
from torchvision.utils import save_image

# Function to generate samples for a given class
def generate_samples(generator, class_label, num_samples):
    noise = torch.randn(num_samples, 100).to(device)
    label = torch.ones(num_samples, 2).to(device)
    label[:, class_label] = 1.0
    generated_images = generator(noise, label)
    return generated_images

# Generate samples for class 0
class_0_samples = generate_samples(generator, 0, 2000)

# Generate samples for class 1
class_1_samples = generate_samples(generator, 1, 2000)

# Save the generated samples with suitable format and label in a dataloader
class_0_dataset = torch.utils.data.TensorDataset(class_0_samples, torch.zeros(2000))
class_1_dataset = torch.utils.data.TensorDataset(class_1_samples, torch.ones(2000))

generated_dataloader = torch.utils.data.DataLoader(
    torch.utils.data.ConcatDataset([class_0_dataset, class_1_dataset]),
    batch_size=BATCH_SIZE,
    shuffle=True
)

# Add the generated data to the train_dataloader
train_dataloader = torch.utils.data.DataLoader(
    torch.utils.data.ConcatDataset([train_dataset, generated_dataloader.dataset]),
    batch_size=BATCH_SIZE,
    shuffle=True
)

class_0_samples = len(class_0_dataset)
class_1_samples = len(class_1_dataset)

print("Number of samples in class 0 dataset:", class_0_samples)
print("Number of samples in class 1 dataset:", class_1_samples)

import os
import time
import math
from copy import deepcopy
import os.path as osp
import shutil
from prettytable import PrettyTable
import json

from tqdm import tqdm

import numpy as np
import torch
from torch.cuda import amp
# from torch.utils.tensorboard import SummaryWriter

class Trainer:
    # -----------------------------------------------INITIALIZE TRAINING-------------------------------------------------------------
    def __init__(self, device=device, epochs=EPOCHS, batch_size=BATCH_SIZE, save_dir=SAVE_DIR, train_loader=train_dataloader, valid_loader=test_dataloader, weights=None, verbose=VERBOSE, visualize_plots=VISUALIZE_PLOTS, save_plots=SAVE_PLOTS, model_name=MODEL_NAME, optimizer=OPTIMIZER):
        self.device = device
        self.save_dir = save_dir
        self.batch_size = batch_size
        self.epochs = epochs
        self.use_ema = False
        self.model_name = model_name
        self.weights = weights
        self.visualize_plots = visualize_plots
        self.save_plots = save_plots
        # 0 == nothing || 1 == model architecture || 2 == print optimizer || 3 == model parameters
        self.verbose = verbose
        self.d_losses=[]
        self.g_losses=[]
        self.conf = {'Name' : self.model_name, 'Bacth_size' : self.batch_size, 'Max_iter_num' : '', 'Epochs' : self.epochs, 'Trained_epoch' : 0, 'Optimizer' : '', "Model" : '', 'Parameter_size' : ''}
        self.optimizer_name = optimizer

        temm=0
        tmp_save_dir = self.save_dir
        while osp.exists(tmp_save_dir):
            tmp_save_dir = self.save_dir
            temm+=1
            tmp_save_dir += (str(temm))
        self.save_dir = tmp_save_dir
        del temm


        # get data loader
        self.train_loader, self.valid_loader = train_loader, valid_loader
        self.max_stepnum = len(self.train_loader)
        self.conf["Max_iter_num"] = self.max_stepnum

        # get model
        self.d_model, self.g_model = self.get_model()
        if self.verbose > 2:
            self.count_parameters(self.d_model)
            self.count_parameters(self.g_model)

        # Get optimizer
        self.d_optimizer, self.g_optimizer = self.get_optimizer(optimizer=self.optimizer_name)

        # tensorboard
        # self.tblogger = SummaryWriter(self.save_dir)

# ----------------------------------------------------INITIALIZERS-------------------------------------------------------------------------
    # Get Model
    def get_model(self):
        # Get Model Archutecture From Model Class.
        d_model = Discriminator().to(self.device)
        g_model = Generator().to(self.device)

        # finetune if pretrained model is set
        if self.weights:
            print(f'Loading state_dict from {self.weights} for fine-tuning...')
            g_model.load_state_dict(torch.load(self.weights))
        # Log Model
        if self.verbose > 0:
            print('Generator Model: {}\nDescriminator Model: {}'.format(g_model, d_model))
        self.conf["Generator Model"] = str(g_model)
        self.conf["Descriminator Model"] = str(d_model)
        return d_model, g_model

    def get_optimizer(self, optimizer="Adam", lr0=0.0002, beta1 = 0.5):
        assert optimizer == 'SGD' or 'Adam', 'ERROR: unknown optimizer, use SGD defaulted'
        if optimizer == 'SGD':
            d_optim = torch.optim.SGD(self.d_model.parameters(), lr=lr0, momentum=0.5)
            g_optim = torch.optim.SGD(self.g_model.parameters(), lr=lr0, momentum=0.5)
        elif optimizer == 'Adam':
            d_optim = torch.optim.Adam(self.d_model.parameters(), lr=lr0, betas=(beta1, 0.999))
            g_optim = torch.optim.Adam(self.g_model.parameters(), lr=lr0, betas=(beta1, 0.999))

        if self.verbose > 1:
            print(f"{'Descriminator optimizer:'} {type(d_optim).__name__}")
            print(f"{'Generator optimizer:'} {type(g_optim).__name__}")

        self.conf['Generator Optimizer'] = f"{'Generator optimizer:'} {type(g_optim).__name__}"
        self.conf['Descriminator Optimizer'] = f"{'Descriminator optimizer:'} {type(d_optim).__name__}"

        return d_optim, g_optim

    def count_parameters(self, model):
        table = PrettyTable(["Modules", "Parameters"])
        total_params = 0
        for name, parameter in model.named_parameters():
            if not parameter.requires_grad: continue
            params = parameter.numel()
            table.add_row([name, params])
            total_params+=params
        print(table)
        print(f"Total Trainable Params: {total_params}")
        self.conf["Parameter_size"] = total_params

    def d_loss_function(self, inputs, targets):
        return nn.BCELoss()(inputs, targets)


    def g_loss_function(self, inputs):
        targets = torch.ones([inputs.shape[0], 1])
        targets = targets.to(device)
        return nn.BCELoss()(inputs, targets)
# -------------------------------------------------------------------------------TRAINING PROCESS-----------------------------------------------
    def train_discriminator(self, batch_data):
        real_inputs = batch_data[0].to(device)
        real_labels = batch_data[1].squeeze().to(device)
        # print(real_inputs.shape)
        # print(real_labels)

        real_onehot_label = F.one_hot(torch.arange(2), 2).to(self.device)[real_labels].float()
        # print(real_onehot_label)
        real_outputs = self.d_model(real_inputs, real_onehot_label)

        real_label = torch.ones(real_inputs.shape[0], 1).to(device)

        noise = (torch.rand(real_inputs.shape[0], 100) - 0.5) / 0.5
        noise = noise.to(device)
        fake_inputs = self.g_model(noise, real_onehot_label)
        # print(fake_inputs.shape)
        fake_outputs = self.d_model(fake_inputs, real_onehot_label)
        fake_label = torch.zeros(fake_inputs.shape[0], 1).to(device)

        outputs = torch.cat((real_outputs, fake_outputs), 0)
        targets = torch.cat((real_label, fake_label), 0)

        # Zero the parameter gradients
        self.d_optimizer.zero_grad()

        # Backward propagation
        d_loss = self.d_loss_function(outputs, targets)
        d_loss.backward()
        self.d_optimizer.step()
        return d_loss.item()

    def train_generator(self, batch_data):
        real_inputs = batch_data[0].to(self.device)
        real_labels = batch_data[1].squeeze().to(device)

        real_onehot_label = F.one_hot(torch.arange(2), 2).to(self.device)[real_labels].float()

        noise = (torch.rand(real_inputs.shape[0], 100)-0.5)/0.5
        noise = noise.to(device)

        fake_inputs = self.g_model(noise, real_onehot_label)
        fake_outputs = self.d_model(fake_inputs, real_onehot_label)

        g_loss = self.g_loss_function(fake_outputs)
        self.g_optimizer.zero_grad()
        g_loss.backward()
        self.g_optimizer.step()
        return g_loss.item(), fake_inputs, real_labels
    def save_models(self):
        save_dir = osp.join(self.save_dir, 'models')
        if not osp.exists(save_dir):
            os.makedirs(save_dir)
        torch.save(self.g_model.state_dict(), osp.join(save_dir, 'generator.pt'))
        torch.save(self.d_model.state_dict(), osp.join(save_dir, 'discriminator.pt'))

    def load_models(self):
        load_dir = osp.join(self.save_dir, 'models')
        g_model_path = osp.join(load_dir, 'generator.pt')
        d_model_path = osp.join(load_dir, 'discriminator.pt')
        if not osp.exists(g_model_path) or not osp.exists(d_model_path):
            raise FileNotFoundError("Saved models not found.")
        self.g_model.load_state_dict(torch.load(g_model_path))
        self.d_model.load_state_dict(torch.load(d_model_path))

    # Training Process
    def train(self):
        try:
            # training process prerequisite
            self.start_time = time.time()
            print('Start Training Process \nTime: {}'.format(time.ctime(self.start_time)))

            # Check if models exist in the save directory
            load_dir = osp.join(self.save_dir, 'models')
            if osp.exists(load_dir):
                self.load_models()

            # Epoch Loop
            for self.epoch in range(0, self.epochs):
                try:
                    self.conf["Trained_epoch"] = self.epoch
                    # Training loop
                    self.g_model.train(True)
                    self.d_model.train(True)

                    pbar = enumerate(self.train_loader)
                    pbar = tqdm(pbar, total=self.max_stepnum)
                    for step, batch_data in pbar:
                        d_loss = self.train_discriminator(batch_data)
                        g_loss, fake_inputs, real_labels = self.train_generator(batch_data)

                        self.d_losses.append(d_loss)
                        self.g_losses.append(g_loss)
                        pbar.set_description(
                            f"Epoch: {self.epoch}/{self.epochs}\tDescriminator Loss: {d_loss}\Generator Loss: {g_loss}")
                    del pbar

                except Exception as _:
                    print('ERROR in training steps.')
                    raise
                if self.epoch % 10 == 0:
                    # Save models
                    self.save_models()

                    # Plot Losses
                    self.plot_loss()
                    imgs_numpy = (fake_inputs.data.cpu().numpy() + 1.0) / 2.0
                    sqrtn = int(np.ceil(np.sqrt(imgs_numpy[:64].shape[0])))
                    for index, image in enumerate(imgs_numpy[:64]):
                        plt.subplot(sqrtn, sqrtn, index + 1)
                        plt.imshow(image.reshape(28, 28), cmap='gray')

                    if self.save_plots:
                        save_img_dir = osp.join(self.save_dir, 'images')
                        if not osp.exists(save_img_dir):
                            os.makedirs(save_img_dir)
                        plt.savefig("{}/epoch-{}-img.pdf".format(save_img_dir, self.epoch))

                    if self.visualize_plots:
                        plt.show()
                    print(real_labels[:64])

                # Save Model and Configurations
                self.save()

        except Exception as _:
            print('ERROR in training loop or eval/save model.')
            raise
        finally:
            finish_time = time.time()
            print(f'\nTraining completed in {time.ctime(finish_time)} \nIts Done in: {(time.time() - self.start_time) / 3600:.3f} hours.')


    # -------------------------------------------------------Training Callback after each epoch--------------------------
    def plot_loss(self, train_mean_size=1, val_mean_size=1):
        COLS=3
        ROWS=1
        LINE_WIDTH = 2
        fig, ax = plt.subplots(ROWS, COLS, figsize=(COLS*10, ROWS*10))

        # train_mean_size = self.max_stepnum/self.batch_size

        ax[0].plot(np.arange(len(self.d_losses) / train_mean_size), np.mean(np.array(self.d_losses).reshape(-1, train_mean_size), axis=1), 'r',  label="training loss", linewidth=LINE_WIDTH)
        ax[0].set_title("Discriminator Loss")
        ax[1].plot(np.arange(len(self.g_losses) / val_mean_size), np.mean(np.array(self.g_losses).reshape(-1, val_mean_size), axis=1), 'g',  label="validation loss", linewidth=LINE_WIDTH)
        ax[1].set_title("Generator Loss")
        ax[2].plot(np.arange(len(self.d_losses) / train_mean_size), np.mean(np.array(self.d_losses).reshape(-1, train_mean_size), axis=1), 'r',  label="training loss", linewidth=LINE_WIDTH)
        ax[2].plot(np.arange(len(self.g_losses) / val_mean_size), np.mean(np.array(self.g_losses).reshape(-1, val_mean_size), axis=1), 'g',  label="validation loss", linewidth=LINE_WIDTH)
        ax[2].set_title("Dis/Gen Loss")
        if self.save_plots:
            save_plot_dir = osp.join(self.save_dir, 'plots')
            if not osp.exists(save_plot_dir):
                os.makedirs(save_plot_dir)
            plt.savefig("{}/epoch-{}-loss-plot.pdf".format(save_plot_dir, self.epoch))
        if self.visualize_plots:
            plt.show()

    # -------------------------------------------------------save Model-------------------------------------------
    def save(self):
        # create config object
        conf = json.dumps(self.conf)
        f = open(self.save_dir + "/config.json","w")
        f.write(conf)
        f.close()
        # save model
        save_ckpt_dir = osp.join(self.save_dir, 'weights')
        if not osp.exists(save_ckpt_dir):
            os.makedirs(save_ckpt_dir)
        filename = osp.join(save_ckpt_dir, self.model_name + "-" + str(self.epoch) + '.pt')
        torch.save(self.g_model.state_dict(), filename)

Trainer().train()

def generate_instances(generator, num_instances):
    generator.eval()
    generated_instances = []
    with torch.no_grad():
        for _ in range(num_instances):
            # Generate a random noise vector
            noise = torch.randn(1, 100).to(device)

            # Generate a random label
            label = torch.randint(0, 2, (1,)).to(device)

            # Generate an instance using the generator
            generated_instance = generator(noise, F.one_hot(label, num_classes=2).float())

            generated_instances.append(generated_instance)

    # Concatenate the generated instances
    generated_instances = torch.cat(generated_instances, dim=0)

    return generated_instances

# Load the saved generator model
g_model = Generator()
g_model.load_state_dict(torch.load("/content/runs/models/generator.pt"))
g_model.to(device)

# Generate 2000 instances for each class
num_instances_per_class = 4000
generated_data = generate_instances(generator=g_model, num_instances=num_instances_per_class)

# Convert the generated instances to a dataset
generated_dataset = torch.utils.data.TensorDataset(generated_data, torch.tensor([2] * len(generated_data)))

# Combine the generated dataset with the original dataset
combined_dataset = torch.utils.data.ConcatDataset([train_dataset, generated_dataset])

# Create new dataloaders with the combined dataset
combined_dataloader = torch.utils.data.DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True)

import matplotlib.pyplot as plt

# Access the first sample from the generated_dataset
sample_image, sample_label = generated_dataset[20]

# Move the tensor to the CPU
sample_image_cpu = sample_image.cpu()

# Plot the sample image
plt.imshow(sample_image_cpu.squeeze(), cmap='gray')
plt.title(f"Label: {sample_label}")
plt.axis('off')
plt.show()

test_loader = test_dataloader
val_loader = test_dataloader
train_loader = combined_dataloader

import torchvision.transforms as transforms

data_transform = transforms.Compose([
    transforms.Resize(224),  # Resize the image to 224x224
    transforms.Grayscale(3),  # Convert the image to RGB format
    transforms.ToTensor(),  # Convert data to tensors
    transforms.Normalize(mean=[.5], std=[.5])  # Normalize the data
])

# Apply transformations to train_dataset
train_dataset.transform = data_transform

# Apply transformations to val_dataset
val_dataset.transform = data_transform

# Apply transformations to test_dataset
test_dataset.transform = data_transform

# Update train_loader
train_loader = data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True
)

# Update val_loader
val_loader = data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True
)

# Update test_loader
test_loader = data.DataLoader(
    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True
)

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import torchvision.transforms as transform
from matplotlib import pyplot as plt
from tqdm import tqdm
from torchvision import transforms

# Define variable names and add comments

dataset_name = "breastmnist"  # The name of the dataset
download = True  # Flag to download the dataset if not available locally
dataset_name = dataset_name.lower()  # Convert the dataset name to lowercase

NUM_EPOCHS = 5  # Number of epochs for training
BATCH_SIZE = 16  # Batch size for data loading
lr = 0.0001  # Learning rate for the optimizer


# Import ResNet-50 model
import torchvision.models as models

# Load the pre-trained ResNet-50 model
model = models.resnet50(pretrained=True)

# Replace the last fully connected layer to match the number of output classes
num_classes = 10
model.fc = nn.Linear(model.fc.in_features, num_classes)

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=lr)

# Training loop
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

train_losses = []
val_losses = []
train_accs = []
val_accs = []

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

for epoch in range(NUM_EPOCHS):
    train_loss = 0.0
    val_loss = 0.0
    train_total = 0
    train_correct = 0
    val_total = 0
    val_correct = 0

    # Training
    model.train()
    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - Training'):
        images = images.to(device)
        labels = labels.squeeze().to(device)  # Convert multi-target labels to single-valued labels

        optimizer.zero_grad()

        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item() * images.size(0)

        _, predicted = torch.max(outputs.data, 1)
        train_total += labels.size(0)
        train_correct += (predicted == labels).sum().item()

    # Validation
    model.eval()
    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - Validation'):
            images = images.to(device)
            labels = labels.squeeze().to(device)  # Convert multi-target labels to single-valued labels

            outputs = model(images)
            loss = criterion(outputs, labels)

            val_loss += loss.item() * images.size(0)

            _, predicted = torch.max(outputs.data, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    # Calculate metrics
    train_loss /= len(train_loader.dataset)
    val_loss /= len(val_loader.dataset)
    train_accuracy = train_correct / train_total
    val_accuracy = val_correct / val_total

    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accs.append(train_accuracy)
    val_accs.append(val_accuracy)

    print(f'Epoch {epoch+1}/{NUM_EPOCHS} - Training Loss: {train_loss:.4f} - Training Accuracy: {train_accuracy:.4f} - Validation Loss: {val_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}')

# Plot loss and accuracy
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')
plt.savefig('loss_plot.pdf')

plt.figure(figsize=(10, 5))
plt.plot(train_accs, label='Training Accuracy')
plt.plot(val_accs, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')
plt.savefig('accuracy_plot.pdf')

# Classification report on the test split
model.eval()
test_total = 0
test_correct = 0
test_predictions = []
test_targets = []

with torch.no_grad():
    for images, labels in tqdm(test_loader, desc='Test'):
        images = images.to(device)
        labels = labels.squeeze().to(device)  # Convert multi-target labels to single-valued labels

        outputs = model(images)

        _, predicted = torch.max(outputs.data, 1)
        test_total += labels.size(0)
        test_correct += (predicted == labels).sum().item()

        test_predictions.extend(predicted.cpu().numpy())
        test_targets.extend(labels.cpu().numpy())

test_accuracy = test_correct / test_total
print(f'Test Accuracy: {test_accuracy:.4f}')

# Print classification report
from sklearn.metrics import classification_report
target_names = info['label']
classification_rep = classification_report(test_targets, test_predictions, target_names=target_names)
print(classification_rep)

# Plot confusion matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(test_targets, test_predictions)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=target_names, yticklabels=target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.savefig('confusion_matrix_plot.pdf')

import os
import time
import math
from copy import deepcopy
import os.path as osp
import shutil
from prettytable import PrettyTable
import json

from tqdm import tqdm

import numpy as np
import torch
from torch.cuda import amp

# Import tensorboard
# from torch.utils.tensorboard import SummaryWriter

class Trainer:
    """
    Class for training a model.
    """

    def __init__(self, device=device, epochs=EPOCHS, batch_size=BATCH_SIZE, save_dir=SAVE_DIR, train_loader=train_dataloader, valid_loader=test_dataloader, weights=None, verbose=VERBOSE, visualize_plots=VISUALIZE_PLOTS, save_plots=SAVE_PLOTS, model_name=MODEL_NAME, optimizer=OPTIMIZER):
        """
        Initialize the Trainer object.

        Args:
            device (str): Device to use for training.
            epochs (int): Number of training epochs.
            batch_size (int): Batch size for training.
            save_dir (str): Directory to save the trained model.
            train_loader (DataLoader): DataLoader for training data.
            valid_loader (DataLoader): DataLoader for validation data.
            weights (str): Path to pretrained model weights.
            verbose (int): Level of verbosity for printing information during training.
            visualize_plots (bool): Whether to visualize training plots.
            save_plots (bool): Whether to save training plots.
            model_name (str): Name of the model.
            optimizer (str): Name of the optimizer to use.
        """
        self.device = device
        self.save_dir = save_dir
        self.batch_size = batch_size
        self.epochs = epochs
        self.use_ema = False
        self.model_name = model_name
        self.weights = weights
        self.visualize_plots = visualize_plots
        self.save_plots = save_plots
        # Verbosity levels: 0 = none, 1 = model architecture, 2 = optimizer information, 3 = model parameters
        self.verbose = verbose
        self.d_losses = []
        self.g_losses = []
        self.conf = {'Name': self.model_name, 'Batch_size': self.batch_size, 'Max_iter_num': '', 'Epochs': self.epochs, 'Trained_epoch': 0, 'Optimizer': '', "Model": '', 'Parameter_size': ''}
        self.optimizer_name = optimizer

        # Create a unique save directory
        temm = 0
        tmp_save_dir = self.save_dir
        while osp.exists(tmp_save_dir):
            tmp_save_dir = self.save_dir
            temm += 1
            tmp_save_dir += str(temm)
        self.save_dir = tmp_save_dir
        del temm

        # Get data loaders
        self.train_loader = train_loader
        self.valid_loader = valid_loader
        self.max_stepnum = len(self.train_loader)
        self.conf["Max_iter_num"] = self.max_stepnum

        # Get the model
        self.d_model, self.g_model = self.get_model()
        if self.verbose > 2:
            self.count_parameters(self.d_model)
            self.count_parameters(self.g_model)

        # Get the optimizer
        self.d_optimizer, self.g_optimizer = self.get_optimizer(optimizer=self.optimizer_name)

        # Initialize tensorboard
        # self.tblogger = SummaryWriter(self.save_dir)

    ## INITIALIZERS
    def get_model(self):
        """
        Get the Discriminator and Generator models.

        Returns:
            tuple: Tuple containing the Discriminator and Generator models.
        """
        # Get the Discriminator and Generator models from their respective classes.
        d_model = Discriminator().to(self.device)
        g_model = Generator().to(self.device)

        # Load pretrained weights if provided
        if self.weights:
            print(f'Loading state_dict from {self.weights} for fine-tuning...')
            g_model.load_state_dict(torch.load(self.weights))

        # Log model information
        if self.verbose > 0:
            print('Generator Model:\n', g_model)
            print('Discriminator Model:\n', d_model)
        self.conf["Generator Model"] = str(g_model)
        self.conf["Discriminator Model"] = str(d_model)

        return d_model, g_model

    def get_optimizer(self, optimizer="Adam", lr0=0.0001, beta1=0.5):
        """
        Get the Discriminator and Generator optimizers.

        Args:
            optimizer (str): Name of the optimizer to use. Options: "SGD" or "Adam" (default: "Adam").
            lr0 (float): Learning rate (default: 0.0002).
            beta1 (float): Beta1 parameter for Adam optimizer (default: 0.5).

        Returns:
            tuple: Tuple containing the Discriminator and Generator optimizers.
        """
        assert optimizer in ['SGD', 'Adam'], 'ERROR: Unknown optimizer, defaulting to SGD.'

        if optimizer == 'SGD':
            d_optim = torch.optim.SGD(self.d_model.parameters(), lr=lr0, momentum=0.5)
            g_optim = torch.optim.SGD(self.g_model.parameters(), lr=lr0, momentum=0.5)
        elif optimizer == 'Adam':
            d_optim = torch.optim.Adam(self.d_model.parameters(), lr=lr0, betas=(beta1, 0.999))
            g_optim = torch.optim.Adam(self.g_model.parameters(), lr=lr0, betas=(beta1, 0.999))

        if self.verbose > 1:
            print(f"Discriminator optimizer: {type(d_optim).__name__}")
            print(f"Generator optimizer: {type(g_optim).__name__}")

        self.conf['Generator Optimizer'] = f"Generator optimizer: {type(g_optim).__name__}"
        self.conf['Discriminator Optimizer'] = f"Discriminator optimizer: {type(d_optim).__name__}"

        return d_optim, g_optim

    def count_parameters(self, model):
        """
        Count the number of trainable parameters in a model.

        Args:
            model (nn.Module): The model to count parameters for.
        """
        table = PrettyTable(["Modules", "Parameters"])
        total_params = 0
        for name, parameter in model.named_parameters():
            if not parameter.requires_grad:
                continue
            params = parameter.numel()
            table.add_row([name, params])
            total_params += params
        print(table)
        print(f"Total Trainable Params: {total_params}")
        self.conf["Parameter_size"] = total_params

    def d_loss_function(self, inputs, targets):
        """
        Compute the loss for the Discriminator.

        Args:
            inputs (torch.Tensor): Discriminator inputs.
            targets (torch.Tensor): Discriminator targets.

        Returns:
            torch.Tensor: The loss value.
        """
        return nn.BCELoss()(inputs, targets)

    def g_loss_function(self, inputs):
        """
        Compute the loss for the Generator.

        Args:
            inputs (torch.Tensor): Generator inputs.

        Returns:
            torch.Tensor: The loss value.
        """
        targets = torch.ones([inputs.shape[0], 1]).to(device)
        return nn.BCELoss()(inputs, targets)

    ## TRAINING PROCESS
    def train_discriminator(self, batch_data):
        """
        Train the Discriminator model on a batch of data.

        Args:
            batch_data (tuple): Tuple containing the input data and labels.

        Returns:
            float: The loss value.
        """
        real_inputs = batch_data[0].to(device)
        real_labels = batch_data[1].to(device)

        real_onehot_label = F.one_hot(torch.arange(2), 2).to(self.device)[real_labels].float()

        real_outputs = self.d_model(real_inputs, real_onehot_label)
        real_label = torch.ones(real_inputs.shape[0], 1).to(device)

        noise = (torch.rand(real_inputs.shape[0], 100) - 0.5) / 0.5
        noise = noise.to(device)
        fake_inputs = self.g_model(noise, real_onehot_label)
        fake_outputs = self.d_model(fake_inputs, real_onehot_label)
        fake_label = torch.zeros(fake_inputs.shape[0], 1).to(device)

        outputs = torch.cat((real_outputs, fake_outputs), 0)
        targets = torch.cat((real_label, fake_label), 0)

        # Zero the parameter gradients
        self.d_optimizer.zero_grad()

        # Backward propagation
        d_loss = self.d_loss_function(outputs, targets)
        d_loss.backward()
        self.d_optimizer.step()
        return d_loss.item()

    def train_generator(self, batch_data):
        """
        Train the Generator model on a batch of data.

        Args:
            batch_data (tuple): Tuple containing the input data and labels.

        Returns:
            tuple: Tuple containing the loss value, generated inputs, and real labels.
        """
        real_inputs = batch_data[0].to(self.device)
        real_labels = batch_data[1].to(device)

        real_onehot_label = F.one_hot(torch.arange(2), 2).to(self.device)[real_labels].float()

        noise = (torch.rand(real_inputs.shape[0], 100) - 0.5) / 0.5
        noise = noise.to(device)

        fake_inputs = self.g_model(noise, real_onehot_label)
        fake_outputs = self.d_model(fake_inputs, real_onehot_label)

        g_loss = self.g_loss_function(fake_outputs)
        self.g_optimizer.zero_grad()
        g_loss.backward()
        self.g_optimizer.step()
        return g_loss.item(), fake_inputs, real_labels

    def train(self):
        """
        Train the models.

        This method performs the training process, including training the Discriminator and Generator models
        for the specified number of epochs.
        """
        try:
            # Training process prerequisite
            self.start_time = time.time()
            print('Start Training Process\nTime: {}'.format(time.ctime(self.start_time)))

            # Epoch Loop
            for self.epoch in range(0, self.epochs):
                try:
                    self.conf["Trained_epoch"] = self.epoch

                    # Training loop
                    self.g_model.train(True)
                    self.d_model.train(True)

                    pbar = enumerate(self.train_loader)
                    pbar = tqdm(pbar, total=self.max_stepnum)
                    for step, batch_data in pbar:
                        d_loss = self.train_discriminator(batch_data)
                        g_loss, fake_inputs, real_labels = self.train_generator(batch_data)

                        self.d_losses.append(d_loss)
                        self.g_losses.append(g_loss)
                        pbar.set_description(f"Epoch: {self.epoch}/{self.epochs}\tDiscriminator Loss: {d_loss}\tGenerator Loss: {g_loss}")
                    del pbar

                except Exception as _:
                    print('ERROR in training steps.')
                    raise

                if self.epoch % 10 == 0:
                    # Plot Losses
                    self.plot_loss()
                    imgs_numpy = (fake_inputs.data.cpu().numpy() + 1.0) / 2.0
                    sqrtn = int(np.ceil(np.sqrt(imgs_numpy[:64].shape[0])))
                    for index, image in enumerate(imgs_numpy[:64]):
                        plt.subplot(sqrtn, sqrtn, index + 1)
                        plt.imshow(image.reshape(28, 28), cmap='gray')

                    if self.save_plots:
                        save_img_dir = osp.join(self.save_dir, 'images')
                        if not osp.exists(save_img_dir):
                            os.makedirs(save_img_dir)
                        plt.savefig("{}/epoch-{}-img.pdf".format(save_img_dir, self.epoch))

                    if self.visualize_plots:
                        plt.show()
                    print(real_labels[:64])

                # Save Model and Configurations
                self.save()

        except Exception as _:
            print('ERROR in training loop or eval/save model.')
            raise
        finally:
            finish_time = time.time()
            # print(f'\nTraining completed in {time.ctime(finish_time)} \nIts Done in: {(time.time() - self.start_time) / 3600:.3f} hours.')


    ## Training Callback after each epoch
    def plot_loss(self, train_mean_size=1, val_mean_size=1):
        """
        Plot the training and validation losses.

        Args:
            train_mean_size (int): Size of the training mean.
            val_mean_size (int): Size of the validation mean.
        """
        COLS = 3
        ROWS = 1
        LINE_WIDTH = 2
        fig, ax = plt.subplots(ROWS, COLS, figsize=(COLS * 10, ROWS * 10))

        ax[0].plot(np.arange(len(self.d_losses) / train_mean_size),
                   np.mean(np.array(self.d_losses).reshape(-1, train_mean_size), axis=1), 'r',
                   label="training loss", linewidth=LINE_WIDTH)
        ax[0].set_title("Discriminator Loss")
        ax[1].plot(np.arange(len(self.g_losses) / val_mean_size),
                   np.mean(np.array(self.g_losses).reshape(-1, val_mean_size), axis=1), 'g',
                   label="validation loss", linewidth=LINE_WIDTH)
        ax[1].set_title("Generator Loss")
        ax[2].plot(np.arange(len(self.d_losses) / train_mean_size),
                   np.mean(np.array(self.d_losses).reshape(-1, train_mean_size), axis=1), 'r',
                   label="training loss", linewidth=LINE_WIDTH)
        ax[2].plot(np.arange(len(self.g_losses) / val_mean_size),
                   np.mean(np.array(self.g_losses).reshape(-1, val_mean_size), axis=1), 'g',
                   label="validation loss", linewidth=LINE_WIDTH)
        ax[2].set_title("Dis/Gen Loss")

        if self.save_plots:
            save_plot_dir = osp.join(self.save_dir, 'plots')
            if not osp.exists(save_plot_dir):
                os.makedirs(save_plot_dir)
            plt.savefig("{}/epoch-{}-loss-plot.pdf".format(save_plot_dir, self.epoch))
        if self.visualize_plots:
            plt.show()

    ## Save Model
    def save(self):
        """
        Save the trained model and configurations.
        """
        # Create config object
        conf = json.dumps(self.conf)
        f = open(self.save_dir + "/config.json", "w")
        f.write(conf)
        f.close()

        # Save model
        save_ckpt_dir = osp.join(self.save_dir, 'weights')
        if not osp.exists(save_ckpt_dir):
            os.makedirs(save_ckpt_dir)
        filename = osp.join(save_ckpt_dir, self.model_name + "-" + str(self.epoch) + '.pt')
        torch.save(self.g_model.state_dict(), filename)

## Train the models
Trainer().train()